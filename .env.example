# Stache Configuration

# ===== Quick Start (One API Key) =====
# Get your free OpenAI API key: https://platform.openai.com/
# This is all you need to get started!

OPENAI_API_KEY=sk-...

# ===== Advanced: Upgrade to Claude (Better Quality) =====
# Uncomment these lines to use Claude for LLM synthesis
# (Requires Anthropic API key: https://console.anthropic.com/)

# ANTHROPIC_API_KEY=sk-ant-...
# LLM_PROVIDER=anthropic

# ===== Optional Configuration =====

# Embedding Provider (defaults to openai)
# EMBEDDING_PROVIDER=openai
# COHERE_API_KEY=...  # Uncomment to use Cohere embeddings

# Mixedbread Resilience Configuration
MIXEDBREAD_TIMEOUT=60
MIXEDBREAD_MAX_RETRIES=3
MIXEDBREAD_RETRY_BASE_DELAY=1.0
MIXEDBREAD_RETRY_MAX_DELAY=10.0
MIXEDBREAD_CIRCUIT_BREAKER_THRESHOLD=10
MIXEDBREAD_CIRCUIT_BREAKER_TIMEOUT=60
MIXEDBREAD_CIRCUIT_BREAKER_HALF_OPEN_MAX_CALLS=3
MIXEDBREAD_MAX_CONNECTIONS=50
MIXEDBREAD_MAX_KEEPALIVE_CONNECTIONS=20
MIXEDBREAD_KEEPALIVE_EXPIRY=30

# Vector Database (defaults to local Qdrant)
# VECTORDB_PROVIDER=qdrant
# QDRANT_URL=http://localhost:6333
# QDRANT_COLLECTION=stache

# Chunking Configuration
# Strategies: recursive (default), markdown, semantic, character, transcript
# DEFAULT_CHUNKING_STRATEGY=recursive
# CHUNK_SIZE=2000             # Target size for content (before metadata)
# CHUNK_OVERLAP=200           # Overlap between chunks for context continuity
# CHUNK_MAX_SIZE=2500         # Hard limit including prepended metadata
# CHUNK_METADATA_RESERVE=300  # Reserved space for metadata prefix (speaker, topic, etc.)

# Logging
# LOG_LEVEL=info

# CORS (comma-separated list of allowed origins)
# CORS_ORIGINS=http://localhost:3000,http://localhost:8000
